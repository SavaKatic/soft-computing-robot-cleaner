{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image and Multiple Bounding Boxes Augmentation for Deep Learning\n",
    "\n",
    "## Problem at hand\n",
    "Say we have images for training our Deep Neural Network. We also have separate PASCAL VOC format XML files with coordinates of bounding boxes for objects we are going to train our model to detect. \n",
    "We want to use [TensorFlow Object Detection API](https://github.com/tensorflow/models/tree/master/research/object_detection).\n",
    "To do so we are planning to:\n",
    "1. Convert all XML files into one CSV file that we can feed into TensorFlow Object Detection API\n",
    "2. Resize all images together with the corresponding object bounding boxes\n",
    "3. Augment images to upsample our dataset. Corresponding object bounding boxes should be augmented accordingly\n",
    "4. Document augmented images' new sizes and bounding boxes' coordinates to a CSV file\n",
    "\n",
    "This tutorial will walk you through this process step by step.\n",
    "\n",
    "## Solution\n",
    "\n",
    "At the core of this tutorial we will use amazing [imgaug library](https://github.com/aleju/imgaug). Author has published [tutorials](https://nbviewer.jupyter.org/github/aleju/imgaug-doc/tree/master/notebooks/) on the use of the library and [Documentation](https://imgaug.readthedocs.io/en/latest/index.html) is available as well.\n",
    "\n",
    "But here's a problem:\n",
    "I had to spend a whole day digging through the Documentation and coding up the script for my problem.\n",
    "I decided to share it, so you don't have to waste your time.\n",
    "\n",
    "The easiest way to install imgaug is through Anaconda. Follow this steps in Anaconda prompt to create a virtual environment, install imgaug and activate the environment:\n",
    "```\n",
    "conda create -n myenv python=3.5.6\n",
    "conda config --add channels conda-forge\n",
    "conda install imgaug\n",
    "conda activate myenv\n",
    "```\n",
    "You can refer to [imgaug library GitHub page](https://github.com/aleju/imgaug) for additional info on installation. To work through this tutorial you would need pandas installed as well. If you work through Anaconda it is installed by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will import all required libraries for this tutorial in advance\n",
    "\n",
    "import imgaug as ia\n",
    "ia.seed(1)\n",
    "# imgaug uses matplotlib backend for displaying images\n",
    "%matplotlib inline\n",
    "from imgaug.augmentables.bbs import BoundingBox, BoundingBoxesOnImage\n",
    "from imgaug import augmenters as iaa \n",
    "# imageio library will be used for image input/output\n",
    "import imageio\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "import glob\n",
    "# this library is needed to read XML files for converting it into CSV\n",
    "import xml.etree.ElementTree as ET\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The data: images, XML files, bounding boxes\n",
    "\n",
    "Let's have a look at data we have. You can see basic operations of imgaug library for image loading and augmentation in this [notebook](https://nbviewer.jupyter.org/github/aleju/imgaug-doc/blob/master/notebooks/A01%20-%20Load%20and%20Augment%20an%20Image.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Convert all XML files into one CSV file that we can feed into TensorFlow Object Detection API\n",
    "\n",
    "To convert all separate PASCAL VOC format XML files into one CSV file we will use the [xml_to_csv.py](https://github.com/datitran/raccoon_dataset/blob/master/xml_to_csv.py) code developed by Dan Tran."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that will extract column data for our CSV file\n",
    "def xml_to_csv(path):\n",
    "    xml_list = []\n",
    "    for xml_file in glob.glob(path + '/*.xml'):\n",
    "        tree = ET.parse(xml_file)\n",
    "        root = tree.getroot()\n",
    "        for member in root.findall('object'):\n",
    "            value = (root.find('filename').text,\n",
    "                     int(root.find('size')[0].text),\n",
    "                     int(root.find('size')[1].text),\n",
    "                     member[0].text,\n",
    "                     int(member[4][0].text),\n",
    "                     int(member[4][1].text),\n",
    "                     int(member[4][2].text),\n",
    "                     int(member[4][3].text)\n",
    "                     )\n",
    "            xml_list.append(value)\n",
    "    column_name = ['filename', 'width', 'height', 'class', 'xmin', 'ymin', 'xmax', 'ymax']\n",
    "    xml_df = pd.DataFrame(xml_list, columns=column_name)\n",
    "    return xml_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully converted xml to csv.\n"
     ]
    }
   ],
   "source": [
    "# apply xml_to_csv() function to convert all XML files in images/ folder into labels.csv\n",
    "labels_df = xml_to_csv('images/')\n",
    "labels_df.to_csv(('labels.csv'), index=None)\n",
    "print('Successfully converted xml to csv.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Resize all images together with the corresponding object bounding boxes\n",
    "\n",
    "TensorFlow Object Detection API can be fed by images of different sizes. But your GPU might not be able to handle big pictures. Let's say we want to resize all the picture so the width and height should be 600px or less. \n",
    "\n",
    "To get familiar with basics of image and multiple bounding boxes augmentation refer to this [tutorial](https://nbviewer.jupyter.org/github/aleju/imgaug-doc/blob/master/notebooks/B02%20-%20Augment%20Bounding%20Boxes.ipynb) from imgaug creators.\n",
    "\n",
    "We will create resize_imgaug() function that will take DataFrame as shown in the previous cell and apply resizing augmentation to the image and all corresponding bounding boxes. The function will return DataFrame with updated images and bounding boxes annotations.\n",
    "\n",
    "First, we visualize some of the operation that will take place in the resize_imgaug() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to convert BoundingBoxesOnImage object into DataFrame\n",
    "def bbs_obj_to_df(bbs_object):\n",
    "#     convert BoundingBoxesOnImage object into array\n",
    "    bbs_array = bbs_object.to_xyxy_array()\n",
    "#     convert array into a DataFrame ['xmin', 'ymin', 'xmax', 'ymax'] columns\n",
    "    df_bbs = pd.DataFrame(bbs_array, columns=['xmin', 'ymin', 'xmax', 'ymax'])\n",
    "    return df_bbs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, define resize_imgaug() function. \n",
    "\n",
    "It will take pandas DataFrame with ['filename', 'width', 'height', 'class', 'xmin', 'ymin', 'xmax', 'ymax'] columns. \n",
    "\n",
    "And apply resizing augmentation to the image and all corresponding bounding boxes.Â \n",
    "\n",
    "The function will return DataFrame with updated images and bounding boxes annotations.\n",
    "resize_imgaug() function takes the following variables:\n",
    "- df: pandas DataFrame with ['filename', 'width', 'height', 'class', 'xmin', 'ymin', 'xmax', 'ymax'] columns, labels_df in our case\n",
    "- images_path: path to the folder with original images, 'images/' in our case(don't forget the forward slash)\n",
    "- aug_images_path: path to the folder where augmented images will be stored, e.g. 'aug_images/' (the folder should be created in advance)\n",
    "- image_prefix:  prefix for augmented image filenames, e.g 'aug_'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\savak\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\imgaug\\imgaug.py:182: DeprecationWarning: Function `ContrastNormalization()` is deprecated. Use `imgaug.contrast.LinearContrast` instead.\n",
      "  warn_deprecated(msg, stacklevel=3)\n"
     ]
    }
   ],
   "source": [
    "aug1 = iaa.SomeOf(4, [\n",
    "    iaa.Fliplr(0.5),\n",
    "    iaa.Crop(percent=(0, 0.1)),\n",
    "    iaa.Sometimes(0.5,\n",
    "        iaa.GaussianBlur(sigma=(0, 0.5))\n",
    "    ),\n",
    "    iaa.ContrastNormalization((0.75, 1.5)),\n",
    "    iaa.AdditiveGaussianNoise(loc=0, scale=(0.0, 0.05*255), per_channel=0.5),\n",
    "    iaa.Multiply((0.8, 1.2), per_channel=0.2),\n",
    "    iaa.Affine(\n",
    "        scale={\"x\": (0.8, 1.2), \"y\": (0.8, 1.2)},\n",
    "        translate_percent={\"x\": (-0.2, 0.2), \"y\": (-0.2, 0.2)},\n",
    "        rotate=(-25, 25),\n",
    "        shear=(-8, 8)\n",
    "    )\n",
    "], random_order=True)\n",
    "\n",
    "\n",
    "aug2 = iaa.SomeOf(2, [    \n",
    "    iaa.Affine(scale=(0.5, 1.5)),\n",
    "    iaa.Affine(rotate=(-60, 60)),\n",
    "    iaa.Affine(translate_percent={\"x\": (-0.3, 0.3), \"y\": (-0.3, 0.3)}),\n",
    "    iaa.Fliplr(1),\n",
    "    iaa.Multiply((0.5, 1.5)),\n",
    "    iaa.GaussianBlur(sigma=(1.0, 3.0)),\n",
    "    iaa.AdditiveGaussianNoise(scale=(0.03*255, 0.05*255))\n",
    "])\n",
    "\n",
    "aug3 = iaa.SomeOf(3, [    \n",
    "    iaa.Affine(\n",
    "        scale={\"x\": (0.8, 1.2), \"y\": (0.8, 1.2)},\n",
    "        translate_percent={\"x\": (-0.2, 0.2), \"y\": (-0.2, 0.2)},\n",
    "        rotate=(-25, 25),\n",
    "        shear=(-8, 8)\n",
    "    ),\n",
    "    iaa.Fliplr(1),\n",
    "    iaa.ContrastNormalization((0.75, 1.25)),\n",
    "    iaa.GaussianBlur(sigma=(1.0, 3.0)),\n",
    "    iaa.AdditiveGaussianNoise(scale=(0.03*255, 0.05*255)),\n",
    "    iaa.Crop(percent=(0, 0.1))\n",
    "])\n",
    "\n",
    "aug4 = iaa.SomeOf(4, [    \n",
    "    iaa.Affine(\n",
    "        scale={\"x\": (0.8, 1.2), \"y\": (0.8, 1.2)},\n",
    "        translate_percent={\"x\": (-0.2, 0.2), \"y\": (-0.2, 0.2)},\n",
    "        rotate=(-25, 25),\n",
    "        shear=(-8, 8)\n",
    "    ),\n",
    "    iaa.Fliplr(1),\n",
    "    iaa.Multiply((0.5, 1.5)),\n",
    "    iaa.GaussianBlur(sigma=(1.0, 3.0)),\n",
    "    iaa.AdditiveGaussianNoise(scale=(0.03*255, 0.05*255))\n",
    "], random_order=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "augs = [aug1, aug2, aug3, aug4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's code image_aug() function.\n",
    "\n",
    "It takes the same variables as resize_imgaug(), plus:\n",
    "-augmenter: augmentation parameters of imgaug library. We can now apply custom augmenters.\n",
    "\n",
    "image_aug() function is very similar to resize_imgaug().\n",
    "\n",
    "But there's a caveat.\n",
    "\n",
    "Augmentations, like zooming in and translating the image in x/y directions, can lead to objects of interest (e'g', red pandas) partially or completely move out of image pane. \n",
    "\n",
    "image_aug() function will clip the bounding box if the object of interest is partially outside of image pane. And it will ignore image altogether if no bounding boxes left in image pane."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_aug(df, images_path, aug_images_path, image_prefix, augmentor):\n",
    "    # create data frame which we're going to populate with augmented image info\n",
    "    aug_bbs_xy = pd.DataFrame(columns=\n",
    "                              ['filename','width','height','class', 'xmin', 'ymin', 'xmax', 'ymax']\n",
    "                             )\n",
    "    grouped = df.groupby('filename')\n",
    "    \n",
    "    for filename in df['filename'].unique():\n",
    "    #   get separate data frame grouped by file name\n",
    "        group_df = grouped.get_group(filename)\n",
    "        group_df = group_df.reset_index()\n",
    "        group_df = group_df.drop(['index'], axis=1)   \n",
    "    #   read the image\n",
    "        image = imageio.imread(images_path+filename)\n",
    "    #   get bounding boxes coordinates and write into array        \n",
    "        bb_array = group_df.drop(['filename', 'width', 'height', 'class'], axis=1).values\n",
    "    #   pass the array of bounding boxes coordinates to the imgaug library\n",
    "        bbs = BoundingBoxesOnImage.from_xyxy_array(bb_array, shape=image.shape)\n",
    "    #   apply augmentation on image and on the bounding boxes\n",
    "        image_aug, bbs_aug = augmentor(image=image, bounding_boxes=bbs)\n",
    "    #   disregard bounding boxes which have fallen out of image pane    \n",
    "        bbs_aug = bbs_aug.remove_out_of_image()\n",
    "    #   clip bounding boxes which are partially outside of image pane\n",
    "        bbs_aug = bbs_aug.clip_out_of_image()\n",
    "        \n",
    "    #   don't perform any actions with the image if there are no bounding boxes left in it    \n",
    "        if re.findall('Image...', str(bbs_aug)) == ['Image([]']:\n",
    "            pass\n",
    "        \n",
    "    #   otherwise continue\n",
    "        else:\n",
    "        #   write augmented image to a file\n",
    "            imageio.imwrite(aug_images_path+image_prefix+filename, image_aug)  \n",
    "        #   create a data frame with augmented values of image width and height\n",
    "            info_df = group_df.drop(['xmin', 'ymin', 'xmax', 'ymax'], axis=1)    \n",
    "            for index, _ in info_df.iterrows():\n",
    "                info_df.at[index, 'width'] = image_aug.shape[1]\n",
    "                info_df.at[index, 'height'] = image_aug.shape[0]\n",
    "        #   rename filenames by adding the predifined prefix\n",
    "            info_df['filename'] = info_df['filename'].apply(lambda x: image_prefix+x)\n",
    "        #   create a data frame with augmented bounding boxes coordinates using the function we created earlier\n",
    "            bbs_df = bbs_obj_to_df(bbs_aug)\n",
    "        #   concat all new augmented info into new data frame\n",
    "            aug_df = pd.concat([info_df, bbs_df], axis=1)\n",
    "        #   append rows to aug_bbs_xy data frame\n",
    "            aug_bbs_xy = pd.concat([aug_bbs_xy, aug_df])            \n",
    "    \n",
    "    # return dataframe with updated images and bounding boxes annotations \n",
    "    aug_bbs_xy = aug_bbs_xy.reset_index()\n",
    "    aug_bbs_xy = aug_bbs_xy.drop(['index'], axis=1)\n",
    "    return aug_bbs_xy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply augmentation to our images and save files into 'aug_images/' folder with 'aug1_' prefix.\n",
    "# Write the updated images and bounding boxes annotations to the augmented_images_df dataframe.\n",
    "augmented_images_df_array = []\n",
    "for i in range(0, len(augs)):\n",
    "    augmented_images_df = image_aug(labels_df, 'images/', 'aug_images_new/', 'aug' + str(i) + '_', augs[i])\n",
    "    augmented_images_df_array.append(augmented_images_df)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here using techniques described above to compare original resized images and augmented copies. We will draw bounding boxes as well to make sure they were augmented correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# grouped_resized = labels_df.groupby('filename')\n",
    "# grouped_augmented = augmented_images_df.groupby('filename')\n",
    "# count = 0\n",
    "# fajlovi = []\n",
    "# for filename in labels_df['filename'].unique():    \n",
    "    \n",
    "#     group_r_df = grouped_resized.get_group(filename)\n",
    "#     group_r_df = group_r_df.reset_index()\n",
    "#     group_r_df = group_r_df.drop(['index'], axis=1)\n",
    "#     bb_r_array = group_r_df.drop(['filename', 'width', 'height', 'class'], axis=1).values\n",
    "#     resized_img = imageio.imread('images/'+filename)\n",
    "#     bbs_r = BoundingBoxesOnImage.from_xyxy_array(bb_r_array, shape=resized_img.shape)\n",
    "    \n",
    "#     try:\n",
    "#         group_a_df = grouped_augmented.get_group('aug1_'+filename)\n",
    "#     except:\n",
    "#         fajlovi.append('aug1_' + filename)\n",
    "#         continue\n",
    "#     group_a_df = group_a_df.reset_index()\n",
    "#     group_a_df = group_a_df.drop(['index'], axis=1)\n",
    "#     bb_a_array = group_a_df.drop(['filename', 'width', 'height', 'class'], axis=1).values\n",
    "#     augmented_img = imageio.imread('aug_images/'+'aug1_'+filename)\n",
    "#     bbs_a = BoundingBoxesOnImage.from_xyxy_array(bb_a_array, shape=augmented_img.shape)\n",
    "    \n",
    "#     try:\n",
    "#         ia.imshow(np.hstack([\n",
    "#             bbs_r.draw_on_image(resized_img, size=2),\n",
    "#             bbs_a.draw_on_image(augmented_img, size=2)\n",
    "#             ]))\n",
    "#     except:\n",
    "#         count += 1\n",
    "        \n",
    "# print(count)\n",
    "# print(fajlovi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Document augmented images' new sizes and bounding boxes' coordinates to a CSV file\n",
    "\n",
    "We have two pandas DataFrames: \n",
    "1. resized_images_df - original resized images annotations\n",
    "2. augmented_images_df - augmented images annotations\n",
    "\n",
    "Let's concat them together and save in a new all_labels.csv file. After that we can put all the images in one folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-9-840603556edb>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-9-840603556edb>\"\u001b[1;36m, line \u001b[1;32m3\u001b[0m\n\u001b[1;33m    for i in range(0, len(augs)):\u001b[0m\n\u001b[1;37m                                ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Concat resized_images_df and augmented_images_df together and save in a new all_labels.csv file\n",
    "print('Broj originalnih slika: ', len(labels_df.groupby('filename').Index))\n",
    "for i in range(0, len(augs) - 1):\n",
    "    all_labels_df = pd.concat([labels_df, augmented_images_df_array[i]])\n",
    "    grouped = augmented_images_df_array\n",
    "    print('Broj slika ' + str(i) + '. augmentera: ' + str(len(augmented_images_df_array[i].groupby('filename').Index)))\n",
    "\n",
    "\n",
    "all_labels_df.to_csv('train_labels.csv', index=False)\n",
    "\n",
    "augmented_images_df_array[len(augs) - 1].to_csv('test_labels.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Lastly we can copy all our augmented images in the same folder as original resized images\n",
    "# for file in os.listdir('aug_images'):\n",
    "#     shutil.copy('aug_images/'+file, 'images/'+file)\n",
    "\n",
    "for filename in os.listdir('aug_images_new'):\n",
    "    if (('aug' + str(len(aug) - 1)) in filename):\n",
    "        shutil.copy('aug_images_new/' + filename, 'test/' + filename)\n",
    "    else:\n",
    "        shutil.copy('aug_images_new/' + filename, 'train/' + filename)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
